{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Install VibeVoice [Time 40 seconds]\n",
        "%cd /content/\n",
        "# !git clone https://github.com/microsoft/VibeVoice.git\n",
        "!git clone https://github.com/NeuralFalconYT/VibeVoice.git\n",
        "%cd VibeVoice/\n",
        "!pip install -e .\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "Ly4OqASQUOlu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "cellView": "form",
        "id": "6pTAIU6sTgYQ",
        "outputId": "8907d4a6-9a87-4fa8-d20c-0cc1054a6d17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/VibeVoice-1.5B'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#@title Download Model [Time: 30 Seconds]\n",
        "\n",
        "import os, requests, urllib.request, urllib.error\n",
        "from tqdm.auto import tqdm\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "\n",
        "def download_file(url, download_file_path, redownload=False):\n",
        "    \"\"\"Download a single file with urllib + tqdm progress bar.\"\"\"\n",
        "\n",
        "    base_path = os.path.dirname(download_file_path)\n",
        "    os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "    # skip logic\n",
        "    if os.path.exists(download_file_path):\n",
        "        if redownload:\n",
        "            os.remove(download_file_path)\n",
        "            tqdm.write(f\"‚ôªÔ∏è Redownloading: {os.path.basename(download_file_path)}\")\n",
        "        elif os.path.getsize(download_file_path) > 0:\n",
        "            tqdm.write(f\"‚úîÔ∏è Skipped (already exists): {os.path.basename(download_file_path)}\")\n",
        "            return True\n",
        "\n",
        "    try:\n",
        "        request = urllib.request.urlopen(url)\n",
        "        total = int(request.headers.get('Content-Length', 0))\n",
        "    except urllib.error.URLError as e:\n",
        "        print(f\"‚ùå Error: Unable to open URL: {url}\")\n",
        "        print(f\"Reason: {e.reason}\")\n",
        "        return False\n",
        "\n",
        "    with tqdm(total=total, desc=os.path.basename(download_file_path), unit='B', unit_scale=True, unit_divisor=1024) as progress:\n",
        "        try:\n",
        "            urllib.request.urlretrieve(\n",
        "                url,\n",
        "                download_file_path,\n",
        "                reporthook=lambda count, block_size, total_size: progress.update(block_size)\n",
        "            )\n",
        "        except urllib.error.URLError as e:\n",
        "            print(f\"‚ùå Error: Failed to download {url}\")\n",
        "            print(f\"Reason: {e.reason}\")\n",
        "            return False\n",
        "\n",
        "    tqdm.write(f\"‚¨áÔ∏è Downloaded: {os.path.basename(download_file_path)}\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def download_model(repo_id, download_folder=\"./\", redownload=False):\n",
        "    # normalize empty string as current dir\n",
        "    if not download_folder.strip():\n",
        "        download_folder = \".\"\n",
        "    url = f\"https://huggingface.co/api/models/{repo_id}\"\n",
        "    download_dir = os.path.abspath(f\"{download_folder.rstrip('/')}/{repo_id.split('/')[-1]}\")\n",
        "    os.makedirs(download_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"üìÇ Download directory: {download_dir}\")\n",
        "\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        print(\"‚ùå Error:\", response.status_code, response.text)\n",
        "        return None\n",
        "\n",
        "    data = response.json()\n",
        "    siblings = data.get(\"siblings\", [])\n",
        "    files = [f[\"rfilename\"] for f in siblings]\n",
        "\n",
        "    print(f\"üì¶ Found {len(files)} files in repo '{repo_id}'. Checking cache ...\")\n",
        "\n",
        "    for file in tqdm(files, desc=\"Processing files\", unit=\"file\"):\n",
        "        file_url = f\"https://huggingface.co/{repo_id}/resolve/main/{file}\"\n",
        "        file_path = os.path.join(download_dir, file)\n",
        "        download_file(file_url, file_path, redownload=redownload)\n",
        "\n",
        "    return download_dir\n",
        "Huggingface_Model_Path = 'microsoft/VibeVoice-1.5B'\n",
        "\n",
        "model_folder=download_model(\n",
        "    Huggingface_Model_Path,\n",
        "    download_folder=\"/content/models/\",\n",
        "    redownload=False\n",
        ")\n",
        "clear_output()\n",
        "model_folder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run VibeVoice Gradio App\n",
        "!python /content/VibeVoice/demo/gradio_demo.py \\\n",
        "  --model_path \"/content/models/VibeVoice-1.5B\"  \\\n",
        "  --device \"cuda\" \\\n",
        "  --inference_steps 10 \\\n",
        "  --share"
      ],
      "metadata": {
        "id": "LIouEBGyWZU3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93418160-81a5-4823-ceb6-77f834aca4ae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-23 20:55:52.514638: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1758660952.546668   24028 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1758660952.556077   24028 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1758660952.572394   24028 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758660952.572427   24028 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758660952.572432   24028 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758660952.572435   24028 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-23 20:55:52.577741: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:vibevoice.modular.modular_vibevoice_tokenizer:APEX FusedRMSNorm not available, using native implementation\n",
            "üéôÔ∏è Initializing VibeVoice Demo with Streaming Support...\n",
            "Loading processor & model from /content/models/VibeVoice-1.5B\n",
            "loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B/snapshots/8faed761d45a263340a0528343f099c05c9a4323/vocab.json\n",
            "loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B/snapshots/8faed761d45a263340a0528343f099c05c9a4323/merges.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B/snapshots/8faed761d45a263340a0528343f099c05c9a4323/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B/snapshots/8faed761d45a263340a0528343f099c05c9a4323/tokenizer_config.json\n",
            "loading file chat_template.jinja from cache at None\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'Qwen2Tokenizer'. \n",
            "The class this function is called from is 'VibeVoiceTextTokenizerFast'.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "loading configuration file /content/models/VibeVoice-1.5B/config.json\n",
            "Model config VibeVoiceConfig {\n",
            "  \"acoustic_tokenizer_config\": {\n",
            "    \"causal\": true,\n",
            "    \"channels\": 1,\n",
            "    \"conv_bias\": true,\n",
            "    \"conv_norm\": \"none\",\n",
            "    \"corpus_normalize\": 0.0,\n",
            "    \"decoder_depths\": null,\n",
            "    \"decoder_n_filters\": 32,\n",
            "    \"decoder_ratios\": [\n",
            "      8,\n",
            "      5,\n",
            "      5,\n",
            "      4,\n",
            "      2,\n",
            "      2\n",
            "    ],\n",
            "    \"disable_last_norm\": true,\n",
            "    \"encoder_depths\": \"3-3-3-3-3-3-8\",\n",
            "    \"encoder_n_filters\": 32,\n",
            "    \"encoder_ratios\": [\n",
            "      8,\n",
            "      5,\n",
            "      5,\n",
            "      4,\n",
            "      2,\n",
            "      2\n",
            "    ],\n",
            "    \"fix_std\": 0.5,\n",
            "    \"layer_scale_init_value\": 1e-06,\n",
            "    \"layernorm\": \"RMSNorm\",\n",
            "    \"layernorm_elementwise_affine\": true,\n",
            "    \"layernorm_eps\": 1e-05,\n",
            "    \"mixer_layer\": \"depthwise_conv\",\n",
            "    \"model_type\": \"vibevoice_acoustic_tokenizer\",\n",
            "    \"pad_mode\": \"constant\",\n",
            "    \"std_dist_type\": \"gaussian\",\n",
            "    \"vae_dim\": 64,\n",
            "    \"weight_init_value\": 0.01\n",
            "  },\n",
            "  \"acoustic_vae_dim\": 64,\n",
            "  \"architectures\": [\n",
            "    \"VibeVoiceForConditionalGeneration\"\n",
            "  ],\n",
            "  \"decoder_config\": {\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"hidden_act\": \"silu\",\n",
            "    \"hidden_size\": 1536,\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 8960,\n",
            "    \"max_position_embeddings\": 65536,\n",
            "    \"max_window_layers\": 28,\n",
            "    \"model_type\": \"qwen2\",\n",
            "    \"num_attention_heads\": 12,\n",
            "    \"num_hidden_layers\": 28,\n",
            "    \"num_key_value_heads\": 2,\n",
            "    \"rms_norm_eps\": 1e-06,\n",
            "    \"rope_scaling\": null,\n",
            "    \"rope_theta\": 1000000.0,\n",
            "    \"sliding_window\": null,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"torch_dtype\": \"bfloat16\",\n",
            "    \"use_cache\": true,\n",
            "    \"use_sliding_window\": false,\n",
            "    \"vocab_size\": 151936\n",
            "  },\n",
            "  \"diffusion_head_config\": {\n",
            "    \"ddpm_batch_mul\": 4,\n",
            "    \"ddpm_beta_schedule\": \"cosine\",\n",
            "    \"ddpm_num_inference_steps\": 20,\n",
            "    \"ddpm_num_steps\": 1000,\n",
            "    \"diffusion_type\": \"ddpm\",\n",
            "    \"head_ffn_ratio\": 3.0,\n",
            "    \"head_layers\": 4,\n",
            "    \"hidden_size\": 1536,\n",
            "    \"latent_size\": 64,\n",
            "    \"model_type\": \"vibevoice_diffusion_head\",\n",
            "    \"prediction_type\": \"v_prediction\",\n",
            "    \"rms_norm_eps\": 1e-05,\n",
            "    \"speech_vae_dim\": 64\n",
            "  },\n",
            "  \"model_type\": \"vibevoice\",\n",
            "  \"semantic_tokenizer_config\": {\n",
            "    \"causal\": true,\n",
            "    \"channels\": 1,\n",
            "    \"conv_bias\": true,\n",
            "    \"conv_norm\": \"none\",\n",
            "    \"corpus_normalize\": 0.0,\n",
            "    \"disable_last_norm\": true,\n",
            "    \"encoder_depths\": \"3-3-3-3-3-3-8\",\n",
            "    \"encoder_n_filters\": 32,\n",
            "    \"encoder_ratios\": [\n",
            "      8,\n",
            "      5,\n",
            "      5,\n",
            "      4,\n",
            "      2,\n",
            "      2\n",
            "    ],\n",
            "    \"fix_std\": 0,\n",
            "    \"layer_scale_init_value\": 1e-06,\n",
            "    \"layernorm\": \"RMSNorm\",\n",
            "    \"layernorm_elementwise_affine\": true,\n",
            "    \"layernorm_eps\": 1e-05,\n",
            "    \"mixer_layer\": \"depthwise_conv\",\n",
            "    \"model_type\": \"vibevoice_semantic_tokenizer\",\n",
            "    \"pad_mode\": \"constant\",\n",
            "    \"std_dist_type\": \"none\",\n",
            "    \"vae_dim\": 128,\n",
            "    \"weight_init_value\": 0.01\n",
            "  },\n",
            "  \"semantic_vae_dim\": 128,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\"\n",
            "}\n",
            "\n",
            "loading weights file /content/models/VibeVoice-1.5B/model.safetensors.index.json\n",
            "Instantiating VibeVoiceForConditionalGenerationInference model under default dtype torch.bfloat16.\n",
            "Generate config GenerationConfig {}\n",
            "\n",
            "Instantiating Qwen2Model model under default dtype torch.bfloat16.\n",
            "Instantiating VibeVoiceAcousticTokenizerModel model under default dtype torch.bfloat16.\n",
            "Instantiating VibeVoiceSemanticTokenizerModel model under default dtype torch.bfloat16.\n",
            "Instantiating VibeVoiceDiffusionHead model under default dtype torch.bfloat16.\n",
            "Loading checkpoint shards: 100% 3/3 [00:16<00:00,  5.52s/it]\n",
            "All model checkpoint weights were used when initializing VibeVoiceForConditionalGenerationInference.\n",
            "\n",
            "All the weights of VibeVoiceForConditionalGenerationInference were initialized from the model checkpoint at /content/models/VibeVoice-1.5B.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use VibeVoiceForConditionalGenerationInference for predictions without further training.\n",
            "Generation config file not found, using a generation config created from the model config.\n",
            "Language model attention: sdpa\n",
            "Found 9 voice files in /content/VibeVoice/demo/voices\n",
            "Available voices: en-Alice_woman, en-Alice_woman_bgm, en-Carter_man, en-Frank_man, en-Maya_woman, in-Samuel_man, zh-Anchen_man_bgm, zh-Bowen_man, zh-Xinran_woman\n",
            "Loaded example: 1p_Ch2EN.txt with 1 speakers\n",
            "Loaded example: 1p_abs.txt with 1 speakers\n",
            "Loaded example: 2p_goat.txt with 2 speakers\n",
            "Loaded example: 2p_music.txt with 2 speakers\n",
            "Loaded example: 3p_gpt5.txt with 3 speakers\n",
            "Skipping 4p_climate_100min.txt: duration 100 minutes exceeds 15-minute limit\n",
            "Skipping 4p_climate_45min.txt: duration 45 minutes exceeds 15-minute limit\n",
            "Successfully loaded 5 example scripts\n",
            "üöÄ Launching demo on port 7860\n",
            "üìÅ Model path: /content/models/VibeVoice-1.5B\n",
            "üé≠ Available voices: 9\n",
            "üî¥ Streaming mode: ENABLED\n",
            "üîí Session isolation: ENABLED\n",
            "* Running on local URL:  http://0.0.0.0:7860\n",
            "* Running on public URL: https://003ec34e0dccd9f2c1.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "Keyboard interruption in main thread... closing server.\n",
            "\n",
            "üõë Shutting down gracefully...\n",
            "Killing tunnel 0.0.0.0:7860 <> https://003ec34e0dccd9f2c1.gradio.live\n"
          ]
        }
      ]
    }
  ]
}